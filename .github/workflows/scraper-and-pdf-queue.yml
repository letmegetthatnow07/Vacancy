name: Scrape + Queue PDFs

on:
  schedule:
    # 7:00 AM IST = 1:30 AM UTC
    - cron: '30 1 * * *'
    # 7:00 PM IST = 1:30 PM UTC
    - cron: '30 13 * * *'
  workflow_dispatch:
    inputs:
      mode:
        description: 'Run mode'
        required: false
        default: 'normal'
        type: choice
        options:
          - normal
          - deep

permissions:
  contents: write
  actions: write

jobs:
  scrape-and-queue:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Pull latest changes (prevent conflicts)
        run: |
          git config user.name "Scraper Bot"
          git config user.email "scraper-bot@users.noreply.github.com"
          git pull --rebase origin main || true

      - name: Run collector (Phase 1)
        run: |
          mkdir -p tmp
          python3 tools/collector.py > tmp/candidates.jsonl 2>&1
          echo "=== Collector Output ==="
          wc -l tmp/candidates.jsonl
          head -1 tmp/candidates.jsonl | python3 -m json.tool | head -20

      - name: Run schema merge (Phase 1)
        run: |
          python3 tools/schema_merge.py data.json tmp/candidates.jsonl data.json 2>&1
          echo "✓ Schema merge complete"
          
          python3 << 'PYTHON_SCRIPT'
          import json
          data = json.load(open('data.json'))
          print(f"Active listings: {len(data.get('jobListings', []))}")
          print(f"Archived listings: {len(data.get('archivedListings', []))}")
          print(f"Applied preserved: {data.get('transparencyInfo', {}).get('appliedPreserved', 0)}")
          PYTHON_SCRIPT

      - name: Run QC + Learn (Phase 1)
        run: |
          MODE="${{ github.event.inputs.mode || 'nightly' }}"
          if [ -z "$MODE" ] || [ "$MODE" = "null" ]; then MODE="nightly"; fi
          echo "Running QC + Learn (mode: $MODE)"
          python3 qc_and_learn.py --mode "$MODE" 2>&1
          echo "✓ QC + Learn complete"

      - name: Queue PDF jobs for OCR (Phase 2 dispatch)
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json, os, sys, subprocess
          
          # Load candidates to find PDF jobs
          pdf_jobs = []
          try:
              for line in open('tmp/candidates.jsonl'):
                  if line.strip():
                      j = json.loads(line)
                      if j.get('flags', {}).get('needs_pdf_review') and j.get('pdfLink'):
                          pdf_jobs.append({
                              'url': j['pdfLink'],
                              'jobId': j['id'],
                              'title': j['title'],
                              'source': j['source']
                          })
          except FileNotFoundError:
              print("[WARN] tmp/candidates.jsonl not found, skipping OCR queue", file=sys.stderr)
              sys.exit(0)
          except json.JSONDecodeError as e:
              print(f"[ERROR] Invalid JSON in candidates: {e}", file=sys.stderr)
              sys.exit(1)
          
          if not pdf_jobs:
              print(f"ℹ No jobs need PDF review", file=sys.stderr)
              sys.exit(0)
          
          # Prepare dispatch payload
          payload = {
              "event_type": "process-pdfs",
              "client_payload": {
                  "pdfs": pdf_jobs,
                  "mode": "auto"
              }
          }
          
          # Trigger OCR workflow via GitHub API
          github_token = os.environ.get('GITHUB_TOKEN')
          github_repo = os.environ.get('GITHUB_REPOSITORY')
          
          if not github_token or not github_repo:
              print("[ERROR] GITHUB_TOKEN or GITHUB_REPOSITORY not set", file=sys.stderr)
              sys.exit(1)
          
          api_url = f"https://api.github.com/repos/{github_repo}/dispatches"
          
          try:
              result = subprocess.run([
                  "curl", "-X", "POST", api_url,
                  "-H", "Accept: application/vnd.github.v3+raw+json",
                  "-H", f"Authorization: token {github_token}",
                  "-H", "Content-Type: application/json",
                  "-d", json.dumps(payload),
                  "--fail",  # Exit with code 1 on HTTP error
                  "-w", "\nHTTP Status: %{http_code}\n"
              ], capture_output=True, text=True, timeout=15)
              
              if result.returncode != 0:
                  print(f"[ERROR] GitHub dispatch failed:", file=sys.stderr)
                  print(result.stdout, file=sys.stderr)
                  print(result.stderr, file=sys.stderr)
                  sys.exit(1)
              
              print(f"✓ Queued {len(pdf_jobs)} jobs for OCR processing", file=sys.stderr)
              print(f"Payload: {json.dumps(payload, indent=2)}", file=sys.stderr)
          
          except subprocess.TimeoutExpired:
              print("[ERROR] GitHub dispatch timeout", file=sys.stderr)
              sys.exit(1)
          except Exception as e:
              print(f"[ERROR] GitHub dispatch exception: {e}", file=sys.stderr)
              sys.exit(1)
          PYTHON_SCRIPT

      - name: Validate data.json
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json, sys
          
          try:
              data = json.load(open('data.json'))
              listings = data.get('jobListings', [])
              archived = data.get('archivedListings', [])
              applied_ids = data.get('sections', {}).get('applied', [])
              
              print(f"✓ data.json valid: {len(listings)} active, {len(archived)} archived, {len(applied_ids)} applied")
              
              if len(listings) == 0:
                  print("⚠ WARNING: No active listings (possible scraper failure)")
              
          except json.JSONDecodeError as e:
              print(f"✗ data.json invalid JSON: {e}", file=sys.stderr)
              sys.exit(1)
          except Exception as e:
              print(f"✗ data.json validation error: {e}", file=sys.stderr)
              sys.exit(1)
          PYTHON_SCRIPT

      - name: Commit and push changes
        run: |
          git add data.json health.json learn_registry.json rules.json 2>/dev/null || true
          
          if git diff --cached --quiet; then
            echo "ℹ No changes to commit (database unchanged)"
          else
            git commit -m "chore: scraper run $(date -u +'%Y-%m-%dT%H:%M:%SZ')" \
              -m "Listings: $(python3 -c 'import json; print(len(json.load(open(\"data.json\")).get(\"jobListings\", [])))')" \
              -m "Applied preserved: $(python3 -c 'import json; print(len(json.load(open(\"data.json\")).get(\"sections\", {}).get(\"applied\", [])))')"
            
            echo "Pushing to main..."
            git push origin main
            echo "✓ Changes pushed"
          fi

      - name: Workflow summary
        if: always()
        run: |
          echo "=== Scraper Workflow Summary ==="
          echo "Timestamp: $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
          echo "Status: ${{ job.status }}"
          
          if [ -f data.json ]; then
            python3 -c "import json; d=json.load(open('data.json')); print(f'Listings: {len(d.get(\"jobListings\", []))}'); print(f'Applied: {len(d.get(\"sections\", {}).get(\"applied\", []))}')"
          fi
